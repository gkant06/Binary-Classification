{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b70f0e6d-64bf-44e7-8438-0bcbb58fb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ad3956-f902-46d3-b200-be4ea2e6186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33029 entries, 0 to 33028\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   CunstructedAASeq_cln  33029 non-null  object\n",
      " 1   Id                    33029 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 516.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importing files\n",
    "\n",
    "X_train_0 = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\X_train_kaggle.csv')\n",
    "y_train_0 = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\y_train_kaggle.csv')\n",
    "X_test_0 = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\X_test_kaggle.csv')\n",
    "X_train_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0abb2f1-a99b-458b-9760-3b7b9b7b6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discarding records with length 235 \n",
    "length = [len(X_train_0.CunstructedAASeq_cln[i]) for i in range(len(X_train_0))]\n",
    "X_train_0['_length'] = length\n",
    "X_train_0 = X_train_0[X_train_0['_length'] == 237]\n",
    "\n",
    "# removed 2000 records with length 235, only ones with 237 are remaining\n",
    "X_train_0['_length'].unique()\n",
    "X_train_0.drop(columns = ['_length'] , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd5c757-0b85-4390-8dfd-40704f78ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading descriptor files\n",
    "\n",
    "zscale = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\Z-scale.csv',skiprows=2,usecols = range(1,5))\n",
    "dpps = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\DPPS.csv',skiprows=2,usecols = range(2,12))\n",
    "mswhim = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\MS-WHIM.csv',skiprows=2,usecols = range(2,5))\n",
    "physical = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\Physical.csv',skiprows=2,usecols = range(2,4))\n",
    "stscale = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\ST-scale.csv',skiprows=2,usecols = range(2,10))\n",
    "tscale = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\T-scale.csv',skiprows=2,usecols = range(2,7))\n",
    "vhsescale = pd.read_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\descriptors\\VHSE-scale.csv',skiprows=2,usecols = range(2,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679b86c0-12a4-49a2-a834-de3812b0191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_tables = [zscale, dpps, mswhim, physical, stscale, tscale, vhsescale]\n",
    "consol_desc = pd.concat(descriptor_tables, axis = 'columns')\n",
    "consol_desc = consol_desc.set_index(consol_desc.columns[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad036ec-7a48-42cc-864e-36976515adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "consol_desc = consol_desc.T\n",
    "\n",
    "def encode(seq):    \n",
    "    x = pd.DataFrame([consol_desc[i] for i in seq]).reset_index(drop=True)\n",
    "    x = x.T\n",
    "    e = x.values.flatten()\n",
    "    e = list(e)\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc5ffff7-326e-4870-9c48-5df574318e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just a check\n",
    "dd = pd.DataFrame([consol_desc[i] for i in pep]).reset_index(drop=True)\n",
    "dd = dd.T\n",
    "ff = dd.values.flatten()\n",
    "len(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a8999f-2051-4002-a8e9-35ad5bba6c97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2fca5ca304d1cb3bd9f7a0657729a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9233</th>\n",
       "      <th>9234</th>\n",
       "      <th>9235</th>\n",
       "      <th>9236</th>\n",
       "      <th>9237</th>\n",
       "      <th>9238</th>\n",
       "      <th>9239</th>\n",
       "      <th>9240</th>\n",
       "      <th>9241</th>\n",
       "      <th>9242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31024</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31025</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31026</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31027</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31028</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31029 rows × 9243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  9233  \\\n",
       "0      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "1      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "2      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "3      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "4      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "31024  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "31025  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "31026  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "31027  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "31028  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "\n",
       "       9234  9235  9236  9237  9238  9239  9240  9241  9242  \n",
       "0      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "1      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "2      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "3      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "4      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "31024  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.41 -0.52  0.13  \n",
       "31025  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.19  0.13  \n",
       "31026  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "31027  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.41 -0.52  0.13  \n",
       "31028  0.39  0.83 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "\n",
       "[31029 rows x 9243 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matrix for the training data\n",
    "\n",
    "X_train = X_train_0.copy()\n",
    "\n",
    "\n",
    "X_train['features'] = X_train['CunstructedAASeq_cln'].progress_apply(encode)\n",
    "X_train = pd.DataFrame(X_train['features'].to_list(), columns=range(0,9243))\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f38390fb-1a94-471f-8a5c-d26d3c5f0f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd75f1abd3e468ab3f4a49c4f4a21e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9233</th>\n",
       "      <th>9234</th>\n",
       "      <th>9235</th>\n",
       "      <th>9236</th>\n",
       "      <th>9237</th>\n",
       "      <th>9238</th>\n",
       "      <th>9239</th>\n",
       "      <th>9240</th>\n",
       "      <th>9241</th>\n",
       "      <th>9242</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20681</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20682</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20683</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20684</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.88</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>1.96</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.23</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.23</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20686 rows × 9243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  9233  \\\n",
       "0      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "1      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "2      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "3      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "4      1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "20681  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "20682  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "20683  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "20684  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.88 -2.69  ... -0.13   \n",
       "20685  1.96  2.84  2.23  3.08  3.08 -4.19 -4.92  0.92  2.23 -2.69  ... -0.13   \n",
       "\n",
       "       9234  9235  9236  9237  9238  9239  9240  9241  9242  \n",
       "0      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "1      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "2      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "3      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "4      0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "20681  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "20682  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "20683  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "20684  0.39  0.65 -1.34 -0.68 -0.03  0.02 -0.62 -0.52  0.13  \n",
       "20685  0.39  0.65 -1.34 -0.68  0.56  0.02 -0.62 -0.52  0.13  \n",
       "\n",
       "[20686 rows x 9243 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matrix for the test data\n",
    "\n",
    "X_test = X_test_0.copy()\n",
    "\n",
    "\n",
    "X_test['features'] = X_test['CunstructedAASeq_cln'].progress_apply(encode)\n",
    "X_test = pd.DataFrame(X_test['features'].to_list(), columns=range(0,9243))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4074ea-a184-4c28-bfed-a2ca6b2f2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy file to local\n",
    "X_train.to_csv(r'C:\\Users\\kantg\\OneDrive\\Desktop\\CMU\\ML for Science\\HW4\\check.csv',index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2d752f0-c919-4ac8-98b8-fd6bfd0fe10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "X_train.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1f5a86d-3124-4ebf-aa96-84542e6b3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepping the test data\n",
    "y_train =  y_train_0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3718c286-2d06-423a-a17d-661f70d7392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brightness_Class</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33024</th>\n",
       "      <td>0</td>\n",
       "      <td>7024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33025</th>\n",
       "      <td>0</td>\n",
       "      <td>14012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33026</th>\n",
       "      <td>0</td>\n",
       "      <td>4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33027</th>\n",
       "      <td>1</td>\n",
       "      <td>15193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33028</th>\n",
       "      <td>1</td>\n",
       "      <td>30255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brightness_Class     Id\n",
       "0                     0  11328\n",
       "1                     0   5781\n",
       "2                     0  13681\n",
       "3                     0  30804\n",
       "4                     0  30813\n",
       "...                 ...    ...\n",
       "33024                 0   7024\n",
       "33025                 0  14012\n",
       "33026                 0   4140\n",
       "33027                 1  15193\n",
       "33028                 1  30255\n",
       "\n",
       "[33029 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use X_train to get only IDs that we want for the model\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3dbe26c-78bd-4d7a-b581-36d4a09b93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the training and test data set\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train),columns= X_train.columns, index = X_train.index) \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns= X_test.columns, index = X_test.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3322b927-3acf-440b-831f-cd2a8b702825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kantg\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31029, 33029]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check submission\u001b[39;00m\n\u001b[0;32m      3\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mlog_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrightness_Class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Predicting the test set results\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_test \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1074\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1092\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [31029, 33029]"
     ]
    }
   ],
   "source": [
    "# Check submission\n",
    "\n",
    "log_reg = LogisticRegression(random_state=6,max_iter=200)\n",
    "log_reg.fit(X_train, y_train[['Brightness_Class']])\n",
    "\n",
    "#Predicting the test set results\n",
    "y_test = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848a190-9a91-4c3d-903a-6737bc15ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63c42e-ac38-4547-b0ab-54d4803f9d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6617e3-2857-4c1f-900f-71458c761edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
